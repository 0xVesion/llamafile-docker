version: "3.0"
services:
  llamafile:
    container_name: llamafile
    image: ghcr.io/0xvesion/llamafile-docker:main
    volumes:
     - ./my_model.gguf:/app/model
    ports:
      - 8080:8080
    environment:
      ARGS: --threads 4